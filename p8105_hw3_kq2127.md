p8105\_hw3\_kq2127
================
Kristal Quispe
10/12/2019

## Problem 1

``` r
data("instacart")

instacart %>% 
  group_by(aisle_id, aisle) %>% 
  summarize(n_obs = n()) %>% 
  arrange(desc(n_obs))
```

    ## # A tibble: 134 x 3
    ## # Groups:   aisle_id [134]
    ##    aisle_id aisle                          n_obs
    ##       <int> <chr>                          <int>
    ##  1       83 fresh vegetables              150609
    ##  2       24 fresh fruits                  150473
    ##  3      123 packaged vegetables fruits     78493
    ##  4      120 yogurt                         55240
    ##  5       21 packaged cheese                41699
    ##  6      115 water seltzer sparkling water  36617
    ##  7       84 milk                           32644
    ##  8      107 chips pretzels                 31269
    ##  9       91 soy lactosefree                26240
    ## 10      112 bread                          23635
    ## # ... with 124 more rows

Data set instacart has 1384617 observations and 15 variables. There are
134 aisles, and aisle number 83 (fresh vegetables) has the most items
ordered from (150609).

``` r
instacart %>%
  group_by(aisle_id) %>%
  summarize(n_obs = n()) %>% 
  filter(n_obs > 1000) %>% 
  ggplot(aes(x = aisle_id, y = n_obs)) + 
    geom_point(color = "red", alpha = .5) +
  labs(
    title = "Items Ordered per Aisle",
    x = "Aisle ID",
    y = "Items Ordered (#)"
  ) +
  scale_y_continuous(
    breaks = c(1000, 50000, 150000)
  )
```

![](p8105_hw3_kq2127_files/figure-gfm/unnamed-chunk-2-1.png)<!-- -->

``` r
#look into font size
```

``` r
instacart %>%
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>% 
  group_by(aisle, product_name) %>%
  summarize(n_obs = n()) %>% 
  arrange(aisle, desc(n_obs)) %>% 
  mutate(rank = min_rank(-n_obs)) %>% 
  filter(rank == 1 | rank ==2 | rank ==3) %>% 
  select(Aisle = aisle, Product = product_name, Count = n_obs) %>% 
  knitr::kable()
```

| Aisle                      | Product                                       | Count |
| :------------------------- | :-------------------------------------------- | ----: |
| baking ingredients         | Light Brown Sugar                             |   499 |
| baking ingredients         | Pure Baking Soda                              |   387 |
| baking ingredients         | Cane Sugar                                    |   336 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |    30 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |    28 |
| dog food care              | Small Dog Biscuits                            |    26 |
| packaged vegetables fruits | Organic Baby Spinach                          |  9784 |
| packaged vegetables fruits | Organic Raspberries                           |  5546 |
| packaged vegetables fruits | Organic Blueberries                           |  4966 |

``` r
instacart %>% 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream" ) %>% 
  mutate(
    day = recode(
      order_dow,
      "0" = "Sunday",
      "1" = "Monday",
      "2" = "Tuesday",
      "3" = "Wednesday",
      "4" = "Thursday",
      "5" = "Friday",
      "6" = "Saturday")) %>% 
  group_by(product_name, day) %>% 
  summarize(
    mean_hod = mean(order_hour_of_day)
         )%>% 
  pivot_wider(names_from = day, values_from = mean_hod)%>% 
  select(product_name, Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday) %>% 
  knitr::kable()
```

| product\_name    |   Sunday |   Monday |  Tuesday | Wednesday | Thursday |   Friday | Saturday |
| :--------------- | -------: | -------: | -------: | --------: | -------: | -------: | -------: |
| Coffee Ice Cream | 13.77419 | 14.31579 | 15.38095 |  15.31818 | 15.21739 | 12.26316 | 13.83333 |
| Pink Lady Apples | 13.44118 | 11.36000 | 11.70213 |  14.25000 | 11.55172 | 12.78431 | 11.93750 |

## Problem 2

Data Cleaning

``` r
data("brfss_smart2010")

pb2_df =
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health", response %in% c ("Poor", "Fair", "Good", "Excellent")) %>% 
  mutate(response = as.factor(response)) 
```

Using the datasetâ€¦

``` r
pb2_df %>% 
  filter( year == 2002) %>% 
  group_by(locationabbr) %>%
  summarize(
    n_unique = n_distinct(locationdesc))%>%  
  filter(n_unique >= 7)
```

    ## # A tibble: 6 x 2
    ##   locationabbr n_unique
    ##   <chr>           <int>
    ## 1 CT                  7
    ## 2 FL                  7
    ## 3 MA                  8
    ## 4 NC                  7
    ## 5 NJ                  8
    ## 6 PA                 10

``` r
pb2_df %>% 
  filter( year == 2010) %>% 
  group_by(locationabbr) %>%
  summarize(
    n_unique = n_distinct(locationdesc))%>%  
  filter(n_unique >= 7)
```

    ## # A tibble: 14 x 2
    ##    locationabbr n_unique
    ##    <chr>           <int>
    ##  1 CA                 12
    ##  2 CO                  7
    ##  3 FL                 41
    ##  4 MA                  9
    ##  5 MD                 12
    ##  6 NC                 12
    ##  7 NE                 10
    ##  8 NJ                 19
    ##  9 NY                  9
    ## 10 OH                  8
    ## 11 PA                  7
    ## 12 SC                  7
    ## 13 TX                 16
    ## 14 WA                 10

In 2002 the following states were observed at 7 or more locations: CT,
FL, MA, NC, NJ and PA. In 2010 the following states were observed at 7
or more locations:CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX and
WA.

``` r
pb2_df %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarize(mean_dv = mean(data_value)) %>% 
  ggplot(aes(x = year, y = mean_dv, color = locationabbr)) + 
  geom_point() +
  geom_line() + 
  theme(legend.position = "bottom")
```

    ## Warning: Removed 4 rows containing missing values (geom_point).

    ## Warning: Removed 3 rows containing missing values (geom_path).

![](p8105_hw3_kq2127_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->

``` r
pb2_df %>% 
  filter( year == 2006 | year == 2010, locationabbr == "NY") %>%
  ggplot(aes(x = response, y = data_value, color = year)) + 
  geom_point(alpha = .5) +
  geom_smooth(se = FALSE) + 
  facet_grid(~ year)
```

    ## `geom_smooth()` using method = 'loess' and formula 'y ~ x'

![](p8105_hw3_kq2127_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

## Problem 3

Load, tidy and wrangle data.

``` r
pb3_df = 
  read_csv(
    file = "./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    day_type = case_when(
      day  %in% c ("Saturday", "Sunday") ~ "Weekend",
      day  %in% c ("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "Weekday",
      TRUE      ~"" 
    )) %>% 
  select(week, day_id, day, day_type, everything())
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

After loading the accel data set and tidying it we end up with pb3\_df
data set. This data set has 35 observations with 1444 variables. The
variables in this data set include: week, day\_id, day, day\_type, and
multiple activity variables ranging from activity\_1 to activity\_1440.

``` r
##pb_df = 
##  mutate(mean_activity = colMeans(activity_1:activity_1440, na.rm = TRUE, dims = 1))
```

aggregate accross minutes to create a total activity variable for each
day, and create a table showing these totals. Are any trends apparent?
